{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intel & MobileODT Cervical Cancer Screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# keras\n",
    "from keras.layers.core import Dense, Dropout, Flatten, Activation\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.models import save_model, load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model\n",
    "\n",
    "# image pre-processing\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import cv2\n",
    "\n",
    "# file utils\n",
    "import glob\n",
    "import piexif\n",
    "import shutil\n",
    "\n",
    "# utils\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definining constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 200\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCH = 5\n",
    "LEARN_RATE = 1.0e-2\n",
    "ALL_DIR = 'data/train'\n",
    "TESTING_DIR = 'data/test'\n",
    "TESTING_DIR2 = 'data/test_stg2'\n",
    "VAL_DIR = 'data/val'\n",
    "TR_DIR = 'data/tr'\n",
    "DEBUG_DIR = 'data/debug'\n",
    "SAVED_MODEL = 'final_model.h5'\n",
    "SEED = 42\n",
    "\n",
    "split_train_valid_done = True\n",
    "preload_model = os.path.isfile(SAVED_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove efix metadata\n",
    "This step is only to remove a warning Keras was throwing on the train dataset for incomplete metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_exif(files):\n",
    "    tmp = []\n",
    "    for file in files:\n",
    "        piexif.remove(file)\n",
    "            \n",
    "def pre_process():\n",
    "    type1 = glob.glob(\"{}/Type_1/*.jpg\".format(ALL_DIR))\n",
    "    type2 = glob.glob(\"{}/Type_2/*.jpg\".format(ALL_DIR))\n",
    "    type3 = glob.glob(\"{}/Type_3/*.jpg\".format(ALL_DIR))\n",
    "        \n",
    "    remove_exif(type1)\n",
    "    remove_exif(type2)\n",
    "    remove_exif(type3)\n",
    "    \n",
    "pre_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add additional data to training set\n",
    "\n",
    "I've tried to use the additional data provided on Kaggle, but I didn't notice better results. The reason for this is that the additional data contains many duplicate images or low quality images. Using the ImageDataGenerator from Keras to augment the data will allow to get decent results even with the initial train dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_files(src_dir, dest_dir):\n",
    "    for file in glob.glob(src_dir):\n",
    "        if file not in glob.glob(dest_dir):\n",
    "            shutil.copy(file,dest_dir)\n",
    "            \n",
    "\n",
    "move_files('data/additional_Type_1_v2', 'data/train/Type_1')\n",
    "move_files('data/additional_Type_2_v2', 'data/train/Type_2')\n",
    "move_files('data/additional_Type_3_v2', 'data/train/Type_3')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split training set\n",
    "\n",
    "With this step I'm going to split the training set into training and validation step. The method below select 70% of images \n",
    "from the directory 'train' and copies the images into a new folder called 'tr'. The remaining 30% of images are copied into\n",
    "a directory called 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credits: @daanraman https://github.com/keras-team/keras/issues/5862\n",
    "def split_dataset_into_test_and_train_sets(all_data_dir, training_data_dir, testing_data_dir, testing_data_pct):\n",
    "    # Recreate testing and training directories\n",
    "    \n",
    "    shutil.rmtree(testing_data_dir, ignore_errors=False)\n",
    "    os.makedirs(testing_data_dir)\n",
    "    print(\"Successfully cleaned directory \" + testing_data_dir)\n",
    "\n",
    "    shutil.rmtree(training_data_dir, ignore_errors=False)\n",
    "    os.makedirs(training_data_dir)\n",
    "    print(\"Successfully cleaned directory \" + training_data_dir)\n",
    "\n",
    "    num_training_files = 0\n",
    "    num_testing_files = 0\n",
    "\n",
    "    for subdir, dirs, files in os.walk(all_data_dir):\n",
    "        category_name = os.path.basename(subdir)\n",
    "\n",
    "        # Don't create a subdirectory for the root directory\n",
    "        print(category_name + \" vs \" + os.path.basename(all_data_dir))\n",
    "        if category_name == os.path.basename(all_data_dir):\n",
    "            continue\n",
    "\n",
    "        training_data_category_dir = training_data_dir + '/' + category_name\n",
    "        testing_data_category_dir = testing_data_dir + '/' + category_name\n",
    "\n",
    "        if not os.path.exists(training_data_category_dir):\n",
    "            os.mkdir(training_data_category_dir)\n",
    "\n",
    "        if not os.path.exists(testing_data_category_dir):\n",
    "            os.mkdir(testing_data_category_dir)\n",
    "\n",
    "        for file in files:\n",
    "            input_file = os.path.join(subdir, file)\n",
    "            if np.random.rand(1) < testing_data_pct:\n",
    "                shutil.copy(input_file, testing_data_dir + '/' + category_name + '/' + file)\n",
    "                num_testing_files += 1\n",
    "            else:\n",
    "                shutil.copy(input_file, training_data_dir + '/' + category_name + '/' + file)\n",
    "                num_training_files += 1\n",
    "\n",
    "    print(\"Processed \" + str(num_training_files) + \" training files.\")\n",
    "    print(\"Processed \" + str(num_testing_files) + \" testing files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not split_train_valid_done:\n",
    "    split_dataset_into_test_and_train_sets(ALL_DIR, TR_DIR, VAL_DIR, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment data\n",
    "\n",
    "In this step I'm going to use the ImageDataGenerator method from Keras to augment the training data and rescale all images by a factory of 1.0/255.0\n",
    "\n",
    "I'm going to call the flow_from_directory method to create a generator for the train and validation data that I'm going to use later to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6085 images belonging to 3 classes.\n",
      "Found 1548 images belonging to 3 classes.\n",
      "190 48\n"
     ]
    }
   ],
   "source": [
    "def create_data_generators(validation_set = False):\n",
    "    if not validation_set:\n",
    "        data_generator = ImageDataGenerator(rescale=1./255., rotation_range=25, \n",
    "        width_shift_range=0.1, height_shift_range=0.1, shear_range=0.2,\n",
    "        horizontal_flip=True, fill_mode=\"nearest\")\n",
    "        \n",
    "        return data_generator.flow_from_directory(TR_DIR, target_size=(IMAGE_SIZE, IMAGE_SIZE), shuffle=True, seed=SEED,\n",
    "                                                         class_mode='categorical', batch_size=BATCH_SIZE)\n",
    "    else:\n",
    "        valid_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "        return valid_data_generator.flow_from_directory(VAL_DIR, target_size=(IMAGE_SIZE, IMAGE_SIZE), shuffle=True, seed=SEED,\n",
    "                                                         class_mode='categorical', batch_size=BATCH_SIZE,)\n",
    "        \n",
    "\n",
    "\n",
    "train_generator = create_data_generators()\n",
    "validation_generator = create_data_generators(True)\n",
    "\n",
    "step_size_train=train_generator.n//BATCH_SIZE\n",
    "step_size_valid=validation_generator.n//BATCH_SIZE\n",
    "\n",
    "print(step_size_train, step_size_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "\n",
    "In this step instead of building a model from scratch I'm going to use the weights of a pretrained model called ResNet50 that I can download from the Keras library. The output of this model will be the input layer of my model . \n",
    "\n",
    "I'm also using dropout to reduce the risk of overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 200, 200, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                   (None, 100, 100, 64)  9472        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)    (None, 100, 100, 64)  256         conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 100, 100, 64)  0           bn_conv1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 49, 49, 64)    0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)          (None, 49, 49, 64)    4160        max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizatio (None, 49, 49, 64)    256         res2a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 49, 49, 64)    0           bn2a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)          (None, 49, 49, 64)    36928       activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizatio (None, 49, 49, 64)    256         res2a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 49, 49, 64)    0           bn2a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)          (None, 49, 49, 256)   16640       activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)           (None, 49, 49, 256)   16640       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizatio (None, 49, 49, 256)   1024        res2a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalization (None, 49, 49, 256)   1024        res2a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 49, 49, 256)   0           bn2a_branch2c[0][0]              \n",
      "                                                                   bn2a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 49, 49, 256)   0           add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)          (None, 49, 49, 64)    16448       activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizatio (None, 49, 49, 64)    256         res2b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 49, 49, 64)    0           bn2b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)          (None, 49, 49, 64)    36928       activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizatio (None, 49, 49, 64)    256         res2b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 49, 49, 64)    0           bn2b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)          (None, 49, 49, 256)   16640       activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizatio (None, 49, 49, 256)   1024        res2b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 49, 49, 256)   0           bn2b_branch2c[0][0]              \n",
      "                                                                   activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 49, 49, 256)   0           add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)          (None, 49, 49, 64)    16448       activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizatio (None, 49, 49, 64)    256         res2c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 49, 49, 64)    0           bn2c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)          (None, 49, 49, 64)    36928       activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizatio (None, 49, 49, 64)    256         res2c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 49, 49, 64)    0           bn2c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)          (None, 49, 49, 256)   16640       activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizatio (None, 49, 49, 256)   1024        res2c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, 49, 49, 256)   0           bn2c_branch2c[0][0]              \n",
      "                                                                   activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 49, 49, 256)   0           add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)          (None, 25, 25, 128)   32896       activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizatio (None, 25, 25, 128)   512         res3a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 25, 25, 128)   0           bn3a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)          (None, 25, 25, 128)   147584      activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizatio (None, 25, 25, 128)   512         res3a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 25, 25, 128)   0           bn3a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)          (None, 25, 25, 512)   66048       activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)           (None, 25, 25, 512)   131584      activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizatio (None, 25, 25, 512)   2048        res3a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalization (None, 25, 25, 512)   2048        res3a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_4 (Add)                      (None, 25, 25, 512)   0           bn3a_branch2c[0][0]              \n",
      "                                                                   bn3a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 25, 25, 512)   0           add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)          (None, 25, 25, 128)   65664       activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizatio (None, 25, 25, 128)   512         res3b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 25, 25, 128)   0           bn3b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)          (None, 25, 25, 128)   147584      activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizatio (None, 25, 25, 128)   512         res3b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 25, 25, 128)   0           bn3b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)          (None, 25, 25, 512)   66048       activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizatio (None, 25, 25, 512)   2048        res3b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_5 (Add)                      (None, 25, 25, 512)   0           bn3b_branch2c[0][0]              \n",
      "                                                                   activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 25, 25, 512)   0           add_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)          (None, 25, 25, 128)   65664       activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizatio (None, 25, 25, 128)   512         res3c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 25, 25, 128)   0           bn3c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)          (None, 25, 25, 128)   147584      activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizatio (None, 25, 25, 128)   512         res3c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 25, 25, 128)   0           bn3c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)          (None, 25, 25, 512)   66048       activation_18[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizatio (None, 25, 25, 512)   2048        res3c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_6 (Add)                      (None, 25, 25, 512)   0           bn3c_branch2c[0][0]              \n",
      "                                                                   activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 25, 25, 512)   0           add_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)          (None, 25, 25, 128)   65664       activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizatio (None, 25, 25, 128)   512         res3d_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 25, 25, 128)   0           bn3d_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)          (None, 25, 25, 128)   147584      activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizatio (None, 25, 25, 128)   512         res3d_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 25, 25, 128)   0           bn3d_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)          (None, 25, 25, 512)   66048       activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizatio (None, 25, 25, 512)   2048        res3d_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_7 (Add)                      (None, 25, 25, 512)   0           bn3d_branch2c[0][0]              \n",
      "                                                                   activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 25, 25, 512)   0           add_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)          (None, 13, 13, 256)   131328      activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizatio (None, 13, 13, 256)   1024        res4a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 13, 13, 256)   0           bn4a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)          (None, 13, 13, 256)   590080      activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizatio (None, 13, 13, 256)   1024        res4a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 13, 13, 256)   0           bn4a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)          (None, 13, 13, 1024)  263168      activation_24[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)           (None, 13, 13, 1024)  525312      activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizatio (None, 13, 13, 1024)  4096        res4a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalization (None, 13, 13, 1024)  4096        res4a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_8 (Add)                      (None, 13, 13, 1024)  0           bn4a_branch2c[0][0]              \n",
      "                                                                   bn4a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 13, 13, 1024)  0           add_8[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)          (None, 13, 13, 256)   262400      activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizatio (None, 13, 13, 256)   1024        res4b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 13, 13, 256)   0           bn4b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)          (None, 13, 13, 256)   590080      activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizatio (None, 13, 13, 256)   1024        res4b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, 13, 13, 256)   0           bn4b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)          (None, 13, 13, 1024)  263168      activation_27[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizatio (None, 13, 13, 1024)  4096        res4b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_9 (Add)                      (None, 13, 13, 1024)  0           bn4b_branch2c[0][0]              \n",
      "                                                                   activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, 13, 13, 1024)  0           add_9[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)          (None, 13, 13, 256)   262400      activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizatio (None, 13, 13, 256)   1024        res4c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_29 (Activation)       (None, 13, 13, 256)   0           bn4c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)          (None, 13, 13, 256)   590080      activation_29[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizatio (None, 13, 13, 256)   1024        res4c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_30 (Activation)       (None, 13, 13, 256)   0           bn4c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)          (None, 13, 13, 1024)  263168      activation_30[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizatio (None, 13, 13, 1024)  4096        res4c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_10 (Add)                     (None, 13, 13, 1024)  0           bn4c_branch2c[0][0]              \n",
      "                                                                   activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_31 (Activation)       (None, 13, 13, 1024)  0           add_10[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)          (None, 13, 13, 256)   262400      activation_31[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizatio (None, 13, 13, 256)   1024        res4d_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_32 (Activation)       (None, 13, 13, 256)   0           bn4d_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)          (None, 13, 13, 256)   590080      activation_32[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizatio (None, 13, 13, 256)   1024        res4d_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_33 (Activation)       (None, 13, 13, 256)   0           bn4d_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)          (None, 13, 13, 1024)  263168      activation_33[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizatio (None, 13, 13, 1024)  4096        res4d_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_11 (Add)                     (None, 13, 13, 1024)  0           bn4d_branch2c[0][0]              \n",
      "                                                                   activation_31[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_34 (Activation)       (None, 13, 13, 1024)  0           add_11[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)          (None, 13, 13, 256)   262400      activation_34[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizatio (None, 13, 13, 256)   1024        res4e_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_35 (Activation)       (None, 13, 13, 256)   0           bn4e_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)          (None, 13, 13, 256)   590080      activation_35[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizatio (None, 13, 13, 256)   1024        res4e_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_36 (Activation)       (None, 13, 13, 256)   0           bn4e_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)          (None, 13, 13, 1024)  263168      activation_36[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizatio (None, 13, 13, 1024)  4096        res4e_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_12 (Add)                     (None, 13, 13, 1024)  0           bn4e_branch2c[0][0]              \n",
      "                                                                   activation_34[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_37 (Activation)       (None, 13, 13, 1024)  0           add_12[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)          (None, 13, 13, 256)   262400      activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizatio (None, 13, 13, 256)   1024        res4f_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_38 (Activation)       (None, 13, 13, 256)   0           bn4f_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)          (None, 13, 13, 256)   590080      activation_38[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizatio (None, 13, 13, 256)   1024        res4f_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_39 (Activation)       (None, 13, 13, 256)   0           bn4f_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)          (None, 13, 13, 1024)  263168      activation_39[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizatio (None, 13, 13, 1024)  4096        res4f_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_13 (Add)                     (None, 13, 13, 1024)  0           bn4f_branch2c[0][0]              \n",
      "                                                                   activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_40 (Activation)       (None, 13, 13, 1024)  0           add_13[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)          (None, 7, 7, 512)     524800      activation_40[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizatio (None, 7, 7, 512)     2048        res5a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_41 (Activation)       (None, 7, 7, 512)     0           bn5a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)          (None, 7, 7, 512)     2359808     activation_41[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizatio (None, 7, 7, 512)     2048        res5a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_42 (Activation)       (None, 7, 7, 512)     0           bn5a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)          (None, 7, 7, 2048)    1050624     activation_42[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)           (None, 7, 7, 2048)    2099200     activation_40[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizatio (None, 7, 7, 2048)    8192        res5a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalization (None, 7, 7, 2048)    8192        res5a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_14 (Add)                     (None, 7, 7, 2048)    0           bn5a_branch2c[0][0]              \n",
      "                                                                   bn5a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_43 (Activation)       (None, 7, 7, 2048)    0           add_14[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)          (None, 7, 7, 512)     1049088     activation_43[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizatio (None, 7, 7, 512)     2048        res5b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_44 (Activation)       (None, 7, 7, 512)     0           bn5b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)          (None, 7, 7, 512)     2359808     activation_44[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizatio (None, 7, 7, 512)     2048        res5b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_45 (Activation)       (None, 7, 7, 512)     0           bn5b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)          (None, 7, 7, 2048)    1050624     activation_45[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizatio (None, 7, 7, 2048)    8192        res5b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_15 (Add)                     (None, 7, 7, 2048)    0           bn5b_branch2c[0][0]              \n",
      "                                                                   activation_43[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_46 (Activation)       (None, 7, 7, 2048)    0           add_15[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)          (None, 7, 7, 512)     1049088     activation_46[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizatio (None, 7, 7, 512)     2048        res5c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_47 (Activation)       (None, 7, 7, 512)     0           bn5c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)          (None, 7, 7, 512)     2359808     activation_47[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizatio (None, 7, 7, 512)     2048        res5c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_48 (Activation)       (None, 7, 7, 512)     0           bn5c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)          (None, 7, 7, 2048)    1050624     activation_48[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizatio (None, 7, 7, 2048)    8192        res5c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_16 (Add)                     (None, 7, 7, 2048)    0           bn5c_branch2c[0][0]              \n",
      "                                                                   activation_46[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_49 (Activation)       (None, 7, 7, 2048)    0           add_16[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)      (None, 1, 1, 2048)    0           activation_49[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 2048)          0           avg_pool[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 32)            65568       flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 32)            0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 3)             99          dropout_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 23,653,379\n",
      "Trainable params: 23,600,259\n",
      "Non-trainable params: 53,120\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    base_model = ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS))\n",
    "    x = Flatten()(base_model.output)\n",
    "    \n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    output = Dense(3, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    \n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_model_from_file(file):\n",
    "    return load_model(file)\n",
    "\n",
    "def compile_model(model):\n",
    "    opt4 = optimizers.Adam(lr=LEARN_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer=opt4, loss='categorical_crossentropy', metrics=['accuracy'])  \n",
    "\n",
    "if preload_model:\n",
    "    model = load_model_from_file(SAVED_MODEL)\n",
    "else: \n",
    "    model = build_model()\n",
    "    compile_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 42/190 [=====>........................] - ETA: 946s - loss: 1.3485 - acc: 0.4784"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.4/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 524288 bytes but only got 0. Skipping tag 3\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/usr/lib64/python3.4/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 393216 bytes but only got 0. Skipping tag 3\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/usr/lib64/python3.4/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 33554432 bytes but only got 0. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/usr/lib64/python3.4/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 25165824 bytes but only got 0. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/usr/lib64/python3.4/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131072 bytes but only got 0. Skipping tag 3\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/usr/lib64/python3.4/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 204865536 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/usr/lib64/python3.4/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 205389824 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/usr/lib64/python3.4/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 521601024 bytes but only got 0. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/usr/lib64/python3.4/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 205914112 bytes but only got 11101. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/usr/lib64/python3.4/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3640590336 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/usr/lib64/python3.4/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 99877888 bytes but only got 0. Skipping tag 1029\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 86/190 [============>.................] - ETA: 653s - loss: 1.2537 - acc: 0.4920"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.4/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 495583232 bytes but only got 0. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/usr/lib64/python3.4/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 205914112 bytes but only got 10704. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/190 [============================>.] - ETA: 6s - loss: 1.1230 - acc: 0.5051 Epoch 00000: val_loss improved from inf to 1.00179, saving model to final_model.h5\n",
      "190/190 [==============================] - 1477s - loss: 1.1226 - acc: 0.5051 - val_loss: 1.0018 - val_acc: 0.5267\n",
      "Epoch 2/5\n",
      "189/190 [============================>.] - ETA: 5s - loss: 1.0209 - acc: 0.5059 Epoch 00001: val_loss improved from 1.00179 to 1.00092, saving model to final_model.h5\n",
      "190/190 [==============================] - 1422s - loss: 1.0208 - acc: 0.5062 - val_loss: 1.0009 - val_acc: 0.5254\n",
      "Epoch 3/5\n",
      "189/190 [============================>.] - ETA: 5s - loss: 1.0171 - acc: 0.5104 Epoch 00002: val_loss did not improve\n",
      "190/190 [==============================] - 1416s - loss: 1.0172 - acc: 0.5105 - val_loss: 1.0019 - val_acc: 0.5247\n",
      "Epoch 4/5\n",
      "189/190 [============================>.] - ETA: 5s - loss: 1.0178 - acc: 0.5103 Epoch 00003: val_loss did not improve\n",
      "190/190 [==============================] - 1415s - loss: 1.0175 - acc: 0.5106 - val_loss: 1.0013 - val_acc: 0.5260\n",
      "Epoch 5/5\n",
      "189/190 [============================>.] - ETA: 5s - loss: 1.0192 - acc: 0.5081 Epoch 00004: val_loss did not improve\n",
      "190/190 [==============================] - 1419s - loss: 1.0191 - acc: 0.5081 - val_loss: 1.0037 - val_acc: 0.5228\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_generator, validation_generator, step_train, step_valid):\n",
    "    checkpoint = ModelCheckpoint(SAVED_MODEL,  \n",
    "                             monitor='val_loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only= True,\n",
    "                             mode='auto') \n",
    "                        \n",
    "    \n",
    "    history = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=step_train,\n",
    "            epochs=NUM_EPOCH,\n",
    "            callbacks=[checkpoint],\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=step_valid)\n",
    "            \n",
    "    model.save(SAVED_MODEL)\n",
    "    return history\n",
    "\n",
    "if not preload_model:\n",
    "    history = train_model(model, train_generator, validation_generator, step_size_train, step_size_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize tranining history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fda7ca6e358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fda75507630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_train_history(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "if history != None:\n",
    "    visualize_train_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 32 batch loss :  1.32622\n",
      "-- 64 batch loss :  1.32622\n",
      "-- 96 batch loss :  1.32285\n",
      "-- 128 batch loss :  1.32789\n",
      "-- 160 batch loss :  1.32622\n",
      "-- 192 batch loss :  1.32622\n",
      "-- 224 batch loss :  1.32285\n",
      "-- 256 batch loss :  1.3279\n",
      "-- 288 batch loss :  1.33126\n",
      "-- 320 batch loss :  1.3279\n",
      "-- 352 batch loss :  1.3279\n",
      "-- 384 batch loss :  1.33126\n",
      "-- 416 batch loss :  1.32453\n",
      "-- 448 batch loss :  1.3279\n",
      "-- 480 batch loss :  1.33126\n",
      "-- 512 batch loss :  1.3279\n",
      "-- 544 batch loss :  1.32958\n",
      "-- 576 batch loss :  1.32622\n",
      "-- 608 batch loss :  1.33126\n",
      "-- 640 batch loss :  1.32958\n",
      "-- 672 batch loss :  1.3279\n",
      "-- 704 batch loss :  1.32958\n",
      "-- 736 batch loss :  1.3279\n",
      "-- 768 batch loss :  1.33126\n",
      "-- 800 batch loss :  1.32958\n",
      "-- 832 batch loss :  1.32958\n",
      "-- 864 batch loss :  1.33294\n",
      "-- 896 batch loss :  1.3279\n",
      "-- 928 batch loss :  1.33294\n",
      "-- 960 batch loss :  1.33126\n",
      "-- 992 batch loss :  1.33126\n",
      "-- 1024 batch loss :  1.33126\n",
      "-- 1056 batch loss :  1.32958\n",
      "-- 1088 batch loss :  1.3279\n",
      "-- 1120 batch loss :  1.33126\n",
      "-- 1152 batch loss :  1.33126\n",
      "-- 1184 batch loss :  1.32958\n",
      "-- 1216 batch loss :  1.3279\n",
      "-- 1248 batch loss :  1.3279\n",
      "-- 1280 batch loss :  1.32958\n",
      "-- 1312 batch loss :  1.32622\n",
      "-- 1344 batch loss :  1.32958\n",
      "-- 1376 batch loss :  1.32285\n",
      "-- 1408 batch loss :  1.32453\n",
      "-- 1440 batch loss :  1.32622\n",
      "-- 1472 batch loss :  1.32622\n",
      "-- 1504 batch loss :  1.33126\n",
      "-- 1536 batch loss :  1.33126\n",
      "-- 1548 batch loss :  1.32846\n",
      "Total loss :  1.32852661209\n"
     ]
    }
   ],
   "source": [
    "def create_data_generator_from_array(raw_data, batch_size, folder, evaluate=False):\n",
    "    labels = [\"Type_1\", \"Type_2\", \"Type_3\"]\n",
    "    while True:\n",
    "        X = np.zeros((batch_size, IMAGE_SIZE, IMAGE_SIZE, CHANNELS), dtype=np.float32)\n",
    "        Y = np.zeros((batch_size, 3), dtype=np.float32)\n",
    "        cnt = 0\n",
    "        for i, (image_name, image_class) in enumerate(raw_data):\n",
    "            file_path = os.path.join(folder,image_class, image_name + '.jpg')        \n",
    "            \n",
    "            image = cv2.imread(file_path)\n",
    "            image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "            #image = image.transpose([2,0,1])\n",
    "            image = image.astype(np.float32) / 255.0\n",
    "            X[cnt, :, :, :] = image\n",
    "            class_index = labels.index(image_class)\n",
    "            Y[cnt, class_index] = 1\n",
    "                \n",
    "            cnt += 1\n",
    "            if cnt == batch_size:\n",
    "                yield (X, Y)\n",
    "                X = np.zeros((batch_size, IMAGE_SIZE, IMAGE_SIZE, CHANNELS), dtype=np.float32)\n",
    "                Y = np.zeros((batch_size, 3), dtype=np.float32)\n",
    "                cnt = 0\n",
    "\n",
    "        if cnt > 0:\n",
    "            X = X[:cnt,:,:,:]\n",
    "            Y = Y[:cnt,:]\n",
    "\n",
    "            yield (X, Y) \n",
    "        \n",
    "        if evaluate:\n",
    "            break\n",
    "\n",
    "\n",
    "def validation_iterator(evaluate=False):\n",
    "    type1 = glob.glob(\"{}/Type_1/*.jpg\".format(VAL_DIR))\n",
    "    type2 = glob.glob(\"{}/Type_2/*.jpg\".format(VAL_DIR))\n",
    "    type3 = glob.glob(\"{}/Type_3/*.jpg\".format(VAL_DIR))\n",
    "    \n",
    "    type1_filenames = extract_filename(type1)\n",
    "    type2_filenames = extract_filename(type2)\n",
    "    type3_filenames = extract_filename(type3)\n",
    "    all_filenames = [type1_filenames, type2_filenames, type3_filenames]\n",
    "    \n",
    "    valid_sizes = [int(len(ids) * 1) for ids in all_filenames]\n",
    "    \n",
    "    \n",
    "    valid_type1 = type1_filenames[:valid_sizes[0]]\n",
    "    valid_type2 = type2_filenames[:valid_sizes[1]]\n",
    "    valid_type3 = type3_filenames[:valid_sizes[2]]\n",
    "\n",
    "    \n",
    "    labels = [\"Type_1\", \"Type_2\", \"Type_3\"]\n",
    "\n",
    "    valid_all = []\n",
    "    \n",
    "\n",
    "    #train\n",
    "    for img in valid_type1:\n",
    "        valid_all.append((img, labels[0]))\n",
    "\n",
    "    for img in valid_type2:\n",
    "        valid_all.append((img, labels[1]))\n",
    "\n",
    "    for img in valid_type3:\n",
    "        valid_all.append((img, labels[2]))\n",
    "\n",
    "    \n",
    "    \n",
    "    validation_iter =  create_data_generator_from_array(valid_all, BATCH_SIZE, VAL_DIR, evaluate)\n",
    "    \n",
    "    return validation_iter\n",
    "\n",
    "def extract_filename(files):\n",
    "    tmp = []\n",
    "    for file in files:\n",
    "        parts = file.split('/')\n",
    "        tmp.append(parts[-1].replace('.jpg', ''))\n",
    "    return np.array(tmp)\n",
    "\n",
    "def evaluate_model(model, validation_generator):\n",
    "    total_loss = 0.0\n",
    "    total_counter = 0 \n",
    "\n",
    "    for X, Y_true in validation_generator:\n",
    "\n",
    "        s = Y_true.shape[0]\n",
    "        total_counter += s\n",
    "\n",
    "        Y_pred = model.predict(X)\n",
    "        loss = logloss_mc(Y_true.astype(np.int), Y_pred)\n",
    "        print(\"--\", total_counter, \"batch loss : \", loss)\n",
    "        total_loss += s * loss\n",
    "    \n",
    "    if (total_counter > 0):\n",
    "        total_loss *= 1.0 / total_counter   \n",
    "    return total_loss\n",
    "\n",
    "def logloss_mc(y_true, y_prob, epsilon=1e-15):\n",
    "    \"\"\" Multiclass logloss\n",
    "    This function is not officially provided by Kaggle, so there is no\n",
    "    guarantee for its correctness.\n",
    "    https://github.com/ottogroup/kaggle/blob/master/benchmark.py\n",
    "    \"\"\"\n",
    "    # normalize\n",
    "    y_prob = y_prob / y_prob.sum(axis=1).reshape(-1, 1)\n",
    "    y_prob = np.maximum(epsilon, y_prob)\n",
    "    y_prob = np.minimum(1 - epsilon, y_prob)\n",
    "    # get probabilities\n",
    "    y = [y_prob[i, j] for (i, j) in enumerate(y_true)]\n",
    "    ll = - np.mean(np.log(y))\n",
    "    return ll\n",
    "\n",
    "vg = validation_iterator(True) \n",
    "\n",
    "total_loss = evaluate_model(model, vg)\n",
    "print(\"Total loss : \", total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4018\n"
     ]
    }
   ],
   "source": [
    "def get_test_dataset_iter(raw_data, batch_size, folder):\n",
    "    labels = [\"Type_1\", \"Type_2\", \"Type_3\"]\n",
    "    while True:\n",
    "        X = np.zeros((batch_size, IMAGE_SIZE, IMAGE_SIZE, CHANNELS), dtype=np.float32)\n",
    "        Y = np.empty((batch_size,), dtype=np.object)\n",
    "        cnt = 0\n",
    "        for i, (image_name, image_class) in enumerate(raw_data):\n",
    "            if image_class == 'Test':\n",
    "                file_path = os.path.join(folder, image_name + '.jpg')\n",
    "            else: \n",
    "                file_path = os.path.join(TESTING_DIR2, image_name + '.jpg')\n",
    "            \n",
    "            image = cv2.imread(file_path)\n",
    "\n",
    "            image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "            #image = image.transpose([2,0,1])\n",
    "            image = image.astype(np.float32) / 255.0\n",
    "            X[cnt, :, :, :] = image\n",
    "            Y[cnt] = str(image_name)\n",
    "            cnt += 1\n",
    "            if cnt == batch_size:\n",
    "                yield (X, Y)\n",
    "                X = np.zeros((batch_size, IMAGE_SIZE, IMAGE_SIZE, CHANNELS), dtype=np.float32)\n",
    "                Y = np.empty((batch_size,), dtype=np.object)\n",
    "                cnt = 0\n",
    "\n",
    "        if cnt > 0:\n",
    "            X = X[:cnt,:,:,:]\n",
    "            Y = Y[:cnt]\n",
    "\n",
    "            yield (X, Y) \n",
    "\n",
    "        break\n",
    "        \n",
    "def gen_submission_dataframe(model, test_iter):\n",
    "    df = pd.DataFrame(columns=['image_name','Type_1','Type_2','Type_3'])\n",
    "    cnt = 0\n",
    "    for X, Y in test_iter:\n",
    "        y_pred = model.predict(X)\n",
    "        s = X.shape[0]\n",
    "\n",
    "        for i in range(s):\n",
    "            df.loc[cnt + i, :] = (Y[i] + '.jpg', ) + tuple(y_pred[i, :])\n",
    "        cnt += s \n",
    "    return df\n",
    "        \n",
    "def make_predictions(model):\n",
    "    test = glob.glob(\"{}/*.jpg\".format(TESTING_DIR))\n",
    "    test2 = glob.glob(\"{}/*.jpg\".format(TESTING_DIR2))\n",
    "\n",
    "    test_filenames = extract_filename(test)\n",
    "    test_filenames2 = extract_filename(test2)\n",
    "\n",
    "    test_all = []\n",
    "    for img in test_filenames:\n",
    "        test_all.append((img, 'Test'))\n",
    "\n",
    "    for img in test_filenames2:\n",
    "        test_all.append((img, 'Test2'))\n",
    "    \n",
    "    print(len(test_all))\n",
    "    test_iter = get_test_dataset_iter(test_all, BATCH_SIZE, TESTING_DIR)\n",
    "    \n",
    "    \n",
    "    return gen_submission_dataframe(model, test_iter)\n",
    "    \n",
    "def save_submission(df):\n",
    "\n",
    "    sub_file = 'submission_' + str(datetime.now().strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "    df.to_csv(sub_file, index=False)\n",
    "\n",
    "def load_model_from_file(file):\n",
    "    return load_model(file)\n",
    "\n",
    "df = make_predictions(model)\n",
    "save_submission(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4018, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
